# -*- coding: utf-8 -*-
"""tele_churn_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16QwzYxADa-UJp8ImcfpkdSr5D0mt-YAD

This is my small project for my prediction model.
"""

!pip install scikit-learn==1.5.2
!pip install pandas scikit-learn xgboost imbalanced-learn matplotlib seaborn

import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from imblearn.over_sampling import SMOTE
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/churn-bigml-80.csv')

# delete the phone column

if "Phone" in df.columns:
    df.drop("Phone", axis=1, inplace=True)
    print("Phone column deleted successfully.")
else:
    print("Phone column not found in the DataFrame.")


# Transform the "Churn" column True/False to 1/0 (Target Variable)

df['Churn'] = df['Churn'].astype(int)

# One-hot-incoding

categorical_columns = ['State', 'Area code', 'International plan', 'Voice mail plan']

df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)

# Selecting Numeric Columns

numeric_columns = df_encoded.select_dtypes(include=['int64', 'float64']).columns.tolist()
if 'Churn' in numeric_columns:
    numeric_columns.remove('Churn') # Excluding the Target


# StadardScaler

scaler = StandardScaler()

df_scaled = df_encoded.copy()
df_scaled[numeric_columns] = scaler.fit_transform(df_encoded[numeric_columns])

"""Now, I will handle the data imbalnce."""

from re import X
x = df_scaled.drop('Churn', axis=1)
y = df_scaled['Churn']

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)

print("Ratio of Churn in the original data train set")
print(y_train.value_counts(normalize=True))


# SMOTE (Oversampling the data)
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

print("Ratio of Churn in the resampled data train set")
print(y_resampled.value_counts(normalize=True))

"""Now, we can see the data is blanced.

XGBOOST
"""

model = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    use_label_encoder=False,
    random_state=42
)

# Grid Search

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 4, 5],
    'learning_rate': [0.05, 0.1, 0.2],
    'subsample': [0.8, 0.9, 1.0],
    'colsample_bytree': [0.8, 0.9, 1.0],
}

grid_search = GridSearchCV(
    estimator=model,
    param_grid=param_grid,
    scoring = 'roc_auc',
    cv=3,
    n_jobs=-1,
    verbose=1
)

# Train GridSearchCV

print("GridSearchCV Train Start...")
grid_search.fit(X_resampled, y_resampled)
print("GridSearchCV Train Finish...")

# Choose the best model

best_model = grid_search.best_estimator_
print("="*50)

# Best Parameter

print("\nBest Parameter")
print(grid_search.best_params_)

# Best Score

print("\nBest Score")
print(grid_search.best_score_)
print("="*50)




print("\nXGBoost Model Train Start...")
model.fit(X_resampled, y_resampled)
print("XGBoost Model Train Finish...")

# Prediction for the test set

y_pred_proba = model.predict_proba(X_test)[:, 1]
y_pred = model.predict(X_test)

print("\nModel Prediction (%)")
print(y_pred_proba[:10])
print("\nModel Prediction (Class)")
print(y_pred[:10])

# Feature Importance

feature_importance = model.feature_importances_
feature_names = X_train.columns

importance_df = pd.DataFrame({
    f"Feature": feature_names,
    f"Importance": feature_importance
})

importance_df = importance_df.sort_values(by='Importance', ascending=False)

# top 10 importances

print("\n Top10 Feature Importance")
print(importance_df.head(10))

# Visualize the importances

plt.figure(figsize=(10, 7))
sns.barplot(x='Importance', y='Feature', data=importance_df.head(10))
plt.title('Top 10 Feature Importance')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

"""Now we will check the model's performance."""

print("\nModel Performance")


# Accuracy

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy:, {accuracy:.4f}")

# Precision

precision = precision_score(y_test, y_pred)
print(f"Precision:, {precision:.4f}")

# Recall

recall = recall_score(y_test, y_pred)
print(f"Recall:, {recall:.4f}")

# F1 score

f1 = f1_score(y_test, y_pred)
print(f"F1 Score:, {f1:.4f}")

# ROC-AUC

roc_auc = roc_auc_score(y_test, y_pred_proba)
print(f"ROC-AUC:, {roc_auc:.4f}")

# Confusion Matrix

conf_matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

# Visualizing the Confusion Matrix

plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=['No Churn (0)', 'Churn (1)'],
            yticklabels=['No Churn (0)', 'Churn (1)'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Actual Churn and Predicted Churn

true_churn = np.sum(y_test)
predicted_churn = np.sum(y_pred)
correctly_predicted_churn = np.sum(np.logical_and(y_test == 1, y_pred == 1))

print("Actual Churn:", true_churn)
print("Predicted Churn:", predicted_churn)
print("Correctly Predicted Churn:", correctly_predicted_churn)